---
title: "Chap13_Jan_10_2020"
author: "Kazu"
date: "1/10/2020"
output:
  pdf_document: default
  html_document:
    keep_md: yes
editor_options:
  chunk_output_type: console
---
# 13. Models with memory
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,error=TRUE,cache = FALSE)
library(rethinking)
library(lme4);library(lmerTest);library(ggplot2);library(reshape2);library(tidyverse);library(readr)
```

# practices
# 12E1 
* Which of the following priors will produce more shrinkage in the estimates? (a) αtank ∼
Normal(0, 1); (b) αtank ∼ Normal(0, 2). Answer: (a)
* 
# 12E2 # learning how to draw math formula in [Rmarkdown/LaTeX](https://en.wikibooks.org/wiki/LaTeX/Mathematics)
* original

$$
y_i \sim Binomial(1, p_i) \\
logit(p_i) = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(0, 10) \\
\beta \sim Normal(0, 1)
$$

* multilevel 
* Is sigma necesary for exponential?

$$
y_i \sim Binomial(1, p_i) \\
logit(p_i) = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(\bar\alpha, \sigma) \\
\bar\alpha \sim Normal(0, 10) \\
\bar{\alpha} \sim Normal(0, 10) \dots with or without is ignored \\ 
\sigma \sim Exponential(1) \\ 
\beta \sim Normal(0, 1)
$$


# 12E3
* Half Cauchy distribution
```{r}
library(extraDistr)
?extraDistr::dhcauchy
```

* original

$$
y_i \sim Normal(\mu_i, \sigma) \\
\mu_i = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(0, 10) \\
\beta \sim Normal(0, 1) \\
\sigma \sim HalfCauchy(0, 2)
$$

* multilevel

$$
y_i \sim Normal(\mu_i, \sigma) \\
\mu_i = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(\bar\alpha, \sigma_2) \\
\bar\alpha \sim Normal(0, 10) \\
\sigma_2 \sim Exponential(1) \\ 
\beta \sim Normal(0, 1) \\
\sigma \sim HalfCauchy(0, 2)
$$

# 12M1 
* Revisit the Reed frog survival data, data(reedfrogs), and add the predation and size treatment variables to the varying intercepts model. Consider models with either main effect alone, both main effects, as well as a model including both and their interaction. Instead of focusing on inferences about these two predictor variables, focus on the inferred variation across tanks. Explain why it changes as it does across models.
```{r}
data(reedfrogs) # 13.1. Example: Multilevel tadpoles
d <- reedfrogs
str(d)
```
```{r}
# make the tank cluster variable
d$tank <- 1:nrow(d)
dat_pred <- list(
    S = d$surv,
    N = d$density,
    tank = d$tank,
    pred = ifelse(d$pred == "no", 0, 1)
    )
dat_pred_size <- list(
    S = d$surv,
    N = d$density,
    tank = d$tank,
    pred = ifelse(d$pred == "no", 0, 1),
    size = ifelse(d$size == "small",0,1)
    )
dat_pred_sze <- list(
    S = d$surv,
    N = d$density,
    tank = d$tank,
    pred = ifelse(d$pred == "no", 0, 1),
    sze = ifelse(d$size == "small",0,1)
    ) # avoiding to use a name, "size" 


```

# original (tank only)

```{r}
m13.2 <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] ,
        a[tank] ~ dnorm( a_bar , sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
             sigma ~ dexp( 1 )
), data=dat_pred_sze , chains=4 , log_lik=TRUE ,cores=2) # cores=2 added by Kazu

```



# tank + pred
```{r}
m13.2.mod.tank.pred <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + b*pred,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        b ~ dnorm(0, 1)
), data=dat_pred , chains=4 , log_lik=TRUE ,cores=2) 
```
* error .... why??? Do not use "a.sigma". Use "a_sigma".
* If I use data_pred_size there is an error: Why?

# tank + pred (using data_prez_size)
```{r}
m13.2.mod.tank.pred <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + b*pred,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        b ~ dnorm(0, 1)
), data=dat_pred_size , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```


# tank + pred (using data_pred_sze)
* no error! Do not use "size" in data list
```{r}
m13.2.mod.tank.pred <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + b*pred,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        b ~ dnorm(0, 1)
), data=dat_pred_sze , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```

```{r}
precis( m13.2.mod.tank.pred , depth=2 )
```

# tank + sze
```{r}
m13.2.mod.tank.sze <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + c*sze ,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        c ~ dnorm(0, 1),
        d ~ dnorm(0, 1)
), data=dat_pred_sze , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```

# tank + pred + size
* error, why?
```{r}
m13.2.mod.tank.pred.size <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + b*pred + c*size,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        b ~ dnorm(0, 1),
        c ~ dnorm(0, 1)
), data=dat_pred_size , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```

```{r}
m13.2.mod.tank.pred.sze <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + b*pred + c*sze,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        b ~ dnorm(0, 1),
        c ~ dnorm(0, 1)
), data=dat_pred_sze , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```
* Do not use "size" as name in a data.


```{r}
precis( m13.2.mod.tank.pred.sze , depth=2 )
```




# tank + pred + sze + pred:sze
```{r}
m13.2.mod.tank.pred.sze <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank] + b*pred + c*sze + d*pred*sze,
        a[tank] ~ dnorm( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1.5 ) ,
        a_sigma ~ dexp( 1 ),
        b ~ dnorm(0, 1),
        c ~ dnorm(0, 1),
        d ~ dnorm(0, 1)
), data=dat_pred_sze , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```



# 12M2
```{r}
compare(m13.2,m13.2.mod.tank.pred,m13.2.mod.tank.sze,m13.2.mod.tank.pred.sze)
```

# 12M3
* Re-estimate the basic Reedfrog varying intercept model,but now using a Cauchy distribution in place of the Gaussian distribution for the varying intercepts. That is, fit this model:

```{r}
m13.2.ex12M3.Cauchy <- ulam(
    alist(
        S ~ dbinom( N , p ) ,
        logit(p) <- a[tank],
        a[tank] ~ dcauchy( a_bar , a_sigma ) ,
        a_bar ~ dnorm( 0 , 1) ,
        a_sigma ~ dcauchy(0,1)
 ), data=dat_pred_sze , chains=4 , log_lik=TRUE ,cores=2,iter=2000) 
```

# compare models
```{r}
precis(m13.2)
precis(m13.2.ex12M3.Cauchy)
compare(m13.2, m13.2.ex12M3.Cauchy)
```

# 
```{r}
prediction.original.Gaussian <- link(m13.2)
prediction.Cauchy <- link(m13.2.ex12M3.Cauchy)
```

# 
```{r}
post.original.Gaussian<-extract.samples(m13.2)
post.original.Cauchy<-extract.samples(m13.2.ex12M3.Cauchy)

d$propsurv.est.Gaussian <- inv_logit( apply( post.original.Gaussian$a , 2 , mean ) ) # across 48 tanks
d$propsurv.est.Cauchy <- inv_logit( apply( post.original.Cauchy$a , 2 , mean ) ) # across 48 tanks
```
# # plot mu of post and compare with raw data
* The raw data could not be true (only by chance).
* Simulated data
* split data for testing could be the way to go
```{r}
d %>% as_tibble() %>% select(tank,propsurv, propsurv.est.Gaussian,propsurv.est.Cauchy) %>% gather("key","value",-1) %>% ggplot(aes(x=tank,y=value,color=key)) + geom_point()

```

# 


# 12H1
```{r}
data("bangladesh")
d <- bangladesh
d$district_id <- as.integer(as.factor(d$district))
str(d)

```

# 
```{r}

```

# 12H2
* Return to the Trolley data, data(Trolley), from Chapter 12. Define and fit a varying intercepts model for these data. Cluster intercepts on individual participants, as indicated by the unique values in the id variable. Include action, intention, and contact as ordinary terms. Compare the varying intercepts model and a model that ignores individuals, using both WAIC and posterior predictions. What is the impact of individual variation in these data?
```{r}
data(Trolley)
d <- Trolley
levels(d$edu)
# relevel deucation level
#edu_levels <- c( 6 , 1 , 8 , 4 , 7 , 2 , 5 , 3 )
# d$edu_new <- edu_levels[ d$edu ]
```

# 
```{r}
dat <- list(
    R = d$response,
    A = d$action,
    I = d$intention,
    C = d$contact )
m12.6 <- ulam(
    alist(
        R ~ dordlogit( phi , cutpoints ),
        phi <- bA*A + bC*C + BI*I ,
        BI <- bI + bIA*A + bIC*C ,
        c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ),
        cutpoints ~ dnorm( 0 , 1.5 )
    ) , data=dat , chains=4 , cores=4 )
precis( m12.6 )
```

# 
```{r}
m12.6.person <- ulam(
    alist(
        R ~ dordlogit( phi , cutpoints ),
        phi <- person[id] + bA*A + bC*C + BI*I ,
        BI <- bI + bIA*A + bIC*C ,
        c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ),
        cutpoints ~ dnorm( 0 , 1.5 )
        person[id] ~ dnorm(0,0.5) 
    ) , data=dat , chains=4 , cores=4 )
```
* J's suggetion for ESS low error (more iter)
* diagnosis with pars
* use small size data





```{r}
sessionInfo()
```

