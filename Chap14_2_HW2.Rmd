---
title: "Chap14_2_HW"
author: "Kazu"
date: "3/13/2020"
output:
  github_document:
    pandoc_args: --webtex
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,error=TRUE,cache = FALSE)
library(rethinking)
library(lme4);library(lmerTest);library(ggplot2);library(reshape2);library(tidyverse);library(readr)
```

# test (my rstan had errors so I checked rstan with simple sample from book)
# multilevel tadpoles
```{r}
data(reedfrogs)
d <- reedfrogs
str(d)
d
# make the tank cluster variable
d$tank <- 1:nrow(d)
dat <- list(
    S = d$surv,
    N = d$density,
    tank = d$tank )

```

* varying intercepts model (= simplelst kind of varying effects) 

$$
Si \sim Bionial(N_i,p_i) \\
logit(p_i) \sim \alpha_{TANK[i]} \\
\alpha_j \sim Normal(0,1.5),\ for\ j=1..48 \\
$$

```{r}
m13.1 <- ulam(
    alist(
        S ~ dbinom( N , p ),
        logit(p) <- a[tank],
        a[tank] ~ dnorm( 0 , 1.5 )
), data=dat, chains=4, log_lik=TRUE ,cores=2) # cores=2 added by Kazu
precis( m13.1 , depth=2 )

```

# the end of test1

# varying slope test (varying slope version of practice 13M3, (eg. m.practice13M3.b) had error, so I cheched varying slope codes from book)
## 14.1.1. Simulate the population. 
```{r R code 14.1}
a <- 3.5
b <- (-1)
sigma_a <- 1
sigma_b <- 0.5
rho <- (-0.7)
# average morning wait time
# average difference afternoon wait time
# std dev in intercepts
# std dev in slopes
# correlation between intercepts and slopes
```

```{r}
Mu <- c( a , b )
```

```{r}
cov_ab <- sigma_a*sigma_b*rho
Sigma <- matrix( c(sigma_a^2,cov_ab,cov_ab,sigma_b^2) , ncol=2 )
```

```{r}
 matrix( c(1,2,3,4) , nrow=2 , ncol=2 )
```

```{r}
sigmas <- c(sigma_a,sigma_b) # standard deviations
Rho <- matrix( c(1,rho,rho,1) , nrow=2 ) # correlation matrix
# now matrix multiply to get covariance matrix
Sigma <- diag(sigmas) %*% Rho %*% diag(sigmas)
```

```{r}
 N_cafes <- 20
```

```{r}
library(MASS)
set.seed(5) # used to replicate example
vary_effects <- mvrnorm( N_cafes , Mu , Sigma )
```

```{r}
a_cafe <- vary_effects[,1]
b_cafe <- vary_effects[,2]
```

```{r}
plot( a_cafe , b_cafe , col=rangi2 ,
    xlab="intercepts (a_cafe)" , ylab="slopes (b_cafe)" )
# overlay population distribution
library(ellipse)
for ( l in c(0.1,0.3,0.5,0.8,0.99) )
    lines(ellipse(Sigma,centre=Mu,level=l),col=col.alpha("black",0.2))
```

# 14.1.2. Simulate observations.
```{r}
set.seed(22)
N_visits <- 10
afternoon <- rep(0:1,N_visits*N_cafes/2)
cafe_id <- rep( 1:N_cafes , each=N_visits )
mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon
sigma <- 0.5  # std dev within cafes
wait <- rnorm( N_visits*N_cafes , mu , sigma )
d <- data.frame( cafe=cafe_id , afternoon=afternoon , wait=wait )
```

# 14.1.3. The varying slopes model.
```{r}
R <- rlkjcorr( 1e4 , K=2 , eta=2 )
dens( R[,1,2] , xlab="correlation" )
```

```{r}
m14.1 <- ulam(
    alist(
        wait ~ normal( mu , sigma ),
        mu <- a_cafe[cafe] + b_cafe[cafe]*afternoon,
        c(a_cafe,b_cafe)[cafe] ~ multi_normal( c(a,b) , Rho , sigma_cafe ),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma_cafe ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(2)
    ) , data=d , chains=4 , cores=2,iter=2000,log_lik=TRUE)
# What is lkj_corr?
?rlkjcorr
?rmultinom # for multi_ormal, correct?
precis(m14.1,depth=3)

```
# the end of varying slope test

# new problems (March 20, 2020)
# 1. 1. Review last weeks material.
# 2. Update last weeks problems if necessary.  Can you fit non-centered models?  Are you using multivariate normal distributions where appropriate?

# 3. Rongkui's Instrumental Variable problem (see earlier email)
# read data
```{r}
Nightbreak_R.Han_data<-read_csv(file.path("..","Nightbreak_02_08_20_Rclub.csv"))
summary(Nightbreak_R.Han_data)
str(Nightbreak_R.Han_data)
table(Nightbreak_R.Han_data$Treatment)
Nightbreak_R.Han_data %>% View()
```

# create Repdocution column
```{r}
Nightbreak_R.Han_data <- Nightbreak_R.Han_data %>% mutate(Reproduction=ifelse(Score<3,0,1)) # 0 = vegetative growth, 1 = reproductive growth
# indexing 
Nightbreak_R.Han_data.index <- Nightbreak_R.Han_data %>% mutate(trt_i=as.integer(as.factor(Treatment))) # 1=Control, 2=Control_NoCurtain, 3=NightBreak
Nightbreak_R.Han_data.index <- Nightbreak_R.Han_data.index %>% 
  mutate(
  loc1_i=ifelse(loc1=="A",0,1),
  loc2_i=ifelse(loc2=="A",0,1),
  loc3_i=ifelse(loc3=="A",0,1),
  loc4_i=ifelse(loc4=="A",0,1),
  loc5_i=ifelse(loc5=="A",0,1)) %>% # 0=A,1=P 
  dplyr::select(Reproduction, contains("_i"))

```

# trt*loc interaction model
```{r}
m.RH.Q4.a <- ulam(alist(
  Reproduction ~ dbinom(1,p),
                  logit(p) <- a[trt_i] + b1*loc1_i + b2*loc2_i + b3*loc3_i + b4*loc4_i + b5*loc5_i + c1[trt_i]*loc1_i + c2[trt_i]*loc2_i +c3[trt_i]*loc3_i + c4[trt_i]*loc4_i + c5[trt_i]*loc5_i,
                  a[trt_i]  ~ dnorm(0,1),
                  b1 ~ dnorm(0, 1),
                  b2 ~ dnorm(0, 1),
                  b3 ~ dnorm(0, 1),
                  b4 ~ dnorm(0, 1),
                  b5 ~ dnorm(0, 1),
                  c1[trt_i] ~ dnorm(0,1),
                  c2[trt_i] ~ dnorm(0,1),
                  c3[trt_i] ~ dnorm(0,1),
                  c4[trt_i] ~ dnorm(0,1),
                  c5[trt_i] ~ dnorm(0,1)),
            data=Nightbreak_R.Han_data.index,
            chains=4,
            cores=2,
            iter=1000,
            log_lik = TRUE)
  
plot(m.RH.Q4.a, depth=2)
```


# 4. Attached are data from an experiment measuring hypocotyl length in ~ 180 natural arabidopsis accessions grown in high and low red:far-red light.  We want to know if there are differences in accessions in their length in high R:FR ("H") and in their response to low R:FR("L").  Also we want to obtain an estimate for hypocotyl length for each accession in high and low R:FR for downstream GWAS analysis.

# Relevant variables:
* length -- hypocotyl length
* line -- unique ID for each accession (you could also use nativename)
* light -- indicator for high or low RFR
* exp -- two independent experiments were done
* plate -- this is an incomplete block design with a subset (10? 12?) of accessions on each plate.
Let's try a variety of increasingly complex models:
* reading data
```{r}
At.hyp.dat <- read_csv("hyp.lengths.both.experiments.labels.csv")
str(At.hyp.dat)
# format dat for exp
At.hyp.dat2 <- At.hyp.dat %>% mutate(expid=ifelse(exp=="A",0,1))
# format dat for plate
At.hyp.dat2 %>% group_by(plate,exp,light,line) %>% summarize(n())
At.hyp.dat2 <- At.hyp.dat2 %>% mutate(plateid = as.integer(as.factor(plate)))
# format for light
At.hyp.dat2 <- At.hyp.dat2 %>% mutate(lightid=ifelse(light=="H",0,1))

```

*1. No pooling
```{r}
At.hyp.dat2.s <- At.hyp.dat2 %>% dplyr::select(length,line,lightid,expid,plateid)
str(At.hyp.dat2.s)
mAt.hyp.nopooling <- ulam(
    alist(
        length ~ normal( mu , sigma ),
        mu <- a[line] + b[line]*lightid  + c[line]*expid + d[line]*plateid,
        a[line] ~ normal(0,1),
        b[line] ~ normal(0,1),
        c[line] ~ normal(0,1),
        d[line] ~ normal(0,1),
        sigma ~ exponential(1),
    ) , data=At.hyp.dat2.s , chains=4 , cores=2,iter=2000,log_lik=TRUE)
plot(mAt.hyp.nopooling, depth=2)
```


2.  Partial pooling of intercepts and slopes for line and intercepts for plate and experiment, but treat each variable separately (no multivariate component).  you might also consider adding an experiment slope effect
```{r}
mAt.hyp.nopooling <- ulam(
    alist(
        length ~ normal( mu , sigma ),
        mu <- a_line[line] + b_line[line]*light + c_line[line]*exp,
        c(a_cafe,b_cafe)[cafe] ~ multi_normal( c(a,b) , Rho , sigma_cafe ),
        a ~ normal(5,2),
        b ~ normal(-1,0.5),
        sigma_cafe ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(2)
    ) , data=At.hyp.dat2 , chains=4 , cores=2,iter=2000,log_lik=TRUE)
```


3. As 2, but use a multivariate normal model for the line slope and intercept effects
```{r}
mAt.hyp.nopooling <- ulam(
    alist(
        length ~ normal( mu , sigma ),
        mu <- a_line[line] + b_line[line]*light + c_line[line]*exp,
        c(a_line,b_line,c_line)[line] ~ multi_normal( c(a,b,c) , Rho , sigma_line ),
        a ~ normal(0,1),
        b ~ normal(0,1),
        c ~ normal(0,1)
        sigma_line ~ exponential(1),
        sigma ~ exponential(1),
        Rho ~ lkj_corr(2)
    ) , data=At.hyp.dat2 , chains=4 , cores=2,iter=2000,log_lik=TRUE)

```

4. As 3, but non-centered
```{r}

```

Evaluate and compare the models.  Is there evidence of line, treatment, and line X treatment effects?  How does the magnitude of the experiment and plate effects compare to the line effects?












# problems
## 13M3. Re-estimate the varying slopes model for the UCBadmit data, now using a non-centered parameterization. Compare the efficiency of the forms of the model, using n_eff. Which is better? Which chain sampled faster?

* modified original m11.8 quad version into ulam
```{r}
data(UCBadmit)
d <- UCBadmit
dat <- list( A=d$admit , N=d$applications , gid=ifelse( d$applicant.gender=="male" , 1 , 2 ),did=rep(1:6,each=2))
dat

m11.8.ulam <- ulam(
    alist(
        A ~ dbinom(N, p),
        logit(p) <- a[gid] + delta[did] ,
        a[gid] ~ dnorm( 0 , 1.5 ) ,
        delta[did] ~ dnorm( 0 , 1.5 )
    ) , data=dat,chains=4,cores=2,iter=4000,log_lik=TRUE)
precis( m11.8.ulam , depth=2 )
plot(m11.8.ulam , depth=2)



```

* multitire? partial pooling model? 
* note: This model is called an interaction non-pooling model.
```{r}
# for non-indexed factor (in this cae gender; gid), use zero and 1. For indexed factor, zero is not addlowed (such as did in this case)
dat2 <- list( A=d$admit , N=d$applications , g=ifelse( d$applicant.gender=="male" , 0 , 1 ),did=rep(1:6,each=2))
# wrong by using data=dat
m.practice13M3.a <- ulam(
    alist(
        A ~ dbinom(N , p ) ,
        ## partial pooling model?
        logit(p) <- a[did] + delta[did]*gid,
          a[did] ~ dnorm( 0 , 1.5 ) ,
          delta[did] ~ dnorm(0,1.5) 
        ) , data=dat , chains=4 , cores=2 , iter=4000,log_lik=TRUE )
precis(m.practice13M3.a, depth=2)
plot(m.practice13M3.a,depth=2)
```
# correct using data=dat2
```{r}
m.practice13M3.a2 <- ulam(
    alist(
        A ~ dbinom(N , p ) ,
        ## partial pooling model?
        logit(p) <- a[did] + delta[did]*g,
          a[did] ~ dnorm( 0 , 1.5 ) ,
          delta[did] ~ dnorm(0,1.5) 
        ) , data=dat2 , chains=4 , cores=2 , iter=4000,log_lik=TRUE )
precis(m.practice13M3.a2, depth=2)
plot(m.practice13M3.a2,depth=2)
```

* the varying slopes model. a_did and b_did are related (correct wording?)
* I modified m14.1 in the book, but does not work. Why? Even Rho ~ lkj_corr(4) instead of Rho ~ lkj_corr(2)
* Because p in dbinom() has to be logit.

```{r}
m.practice13M3.b <- ulam(
    alist(
        A ~ dbinom(N,p),
        p <- a_did[did] + b_did[did]*gid,
        c(a_did,b_did)[did] ~ multi_normal( c(a,b) , Rho , sigma_did ),
        a ~ normal(0,1.5),
        b ~ normal(0,1.5),
        sigma_did ~ exponential(1),
        Rho ~ lkj_corr(4)
    ) , data=dat , chains=4 , cores=2 , iter=4000,log_lik=TRUE)
# error... why?
```

# non index gender (g in dat2)
```{r}
m.practice13M3.b2 <- ulam(
    alist(
        A ~ dbinom(N,p),
        p <- a_did[did] + b_did[did]*g,
        c(a_did,b_did)[did] ~ multi_normal( c(a,b) , Rho , sigma_did ),
        a ~ normal(0,1.5),
        b ~ normal(0,1.5),
        sigma_did ~ exponential(1),
        Rho ~ lkj_corr(4)
    ) , data=dat2 , chains=4 , cores=2 , iter=4000,log_lik=TRUE)
# error... why? becasue p has to be logit
precis(m.practice13M3.b, depth=2)
plot(m.practice13M3.b,depth=2)
```

# logit(p): no error!
```{r}
m.practice13M3.b3 <- ulam(
    alist(
        A ~ dbinom(N,p),
        logit(p) <- a_did[did] + b_did[did]*g,
        c(a_did,b_did)[did] ~ multi_normal( c(a,b) , Rho , sigma_did ),
        a ~ normal(0,1.5),
        b ~ normal(0,1.5),
        sigma_did ~ exponential(1),
        Rho ~ lkj_corr(4)
    ) , data=dat2 , chains=4 , cores=2 , iter=4000,log_lik=TRUE)
precis(m.practice13M3.b3, depth=3)
plot(m.practice13M3.b3,depth=3)
```


# normal? dnorm?
```{r}
m.practice13M3.c <- ulam(
    alist(
        A ~ dbinom(N,p),
        logit(p) <- a_did[did] + b_did[did]*g,
        c(a_did,b_did)[did] ~ multi_normal( c(a,b) , Rho , sigma_did ),
        a ~ dnorm(0,1.5),
        b ~ dnorm(0,1.5),
        sigma_did ~ exponential(1),
        Rho ~ lkj_corr(2)
    ) , data=dat2 , chains=4 , cores=2 , iter=4000,log_lik=TRUE)
precis(m.practice13M3.c, depth=3)
plot(m.practice13M3.c,depth=3)
```

* centered
* This way (modified from m14.2) looks work with error "Warning: There were 272 divergent transitions after warmup.".
```{r}
mpractice13M3.centered <- ulam(
    alist(
      A ~ dbinom(N, p),
      logit(p) <- a[did] + beta[gid, did],
      # adaptive prior
      vector[6]:beta[gid] ~ multi_normal(0, Rho_gid, sigma_gid),
      # fixed priors
      a[did] ~ dnorm(0, 1),
      sigma_gid ~ dexp(1),
      Rho_gid ~ dlkjcorr(4)
    ),
    data = dat,
    chains = 4,
    cores = 4,
    iter = 5000,
    log_lik = T
  )
precis(mpractice13M3.centered,depth=3)
```

* non centered
```{r}
mpractice13M3.noncentered <- ulam(
    alist(
      A ~ dbinom(N, p),
      logit(p) <- a[did] + beta[gid, did],
      # adaptive prior
      #vector[6]:beta[gid] ~ multi_normal(0, Rho_gid, sigma_gid),
      transpars> matrix[gid,6]:beta <-
                compose_noncentered( sigma_gid , L_Rho_gid , z_gid ),
          matrix[6,gid]:z_gid ~ normal( 0 , 1 ),
      # fixed priors
      a[did] ~ dnorm(0, 1),
        vector[6]:sigma_gid ~ dexp(1),
        cholesky_factor_corr[6]:L_Rho_gid ~ lkj_corr_cholesky(2),
      # compute ordinary correlation matrixes from Cholesky factors
        gq> matrix[6,6]:Rho_gid <<- multiply_lower_tri_self_transpose(L_Rho_gid)
    ),
    data = dat,
    chains = 4,
    cores = 4,
    iter = 5000,
    log_lik = T
  )
precis(mpractice13M3.noncentered,depth=3)
```


* compare
```{r}
compare(m11.8.ulam,m.practice13M3.a,mpractice13M3.centered,mpractice13M3.noncentered)
```

* n_eff
"n_eff is a crude estimate of the number of independent sam- ples you managed to get" (book, pg 287). Higher is better (by Julin, March 16, 2020)
```{r}
# extract n_eff values for each model
neff_nc <- precis(mpractice13M3.noncentered,3,pars=c("a","beta"))$n_eff
neff_c <- precis(mpractice13M3.centered,3,pars=c("a","beta"))$n_eff
plot( neff_c , neff_nc , xlab="centered (default)" ,
    ylab="non-centered (cholesky)" , lwd=1.5 )
abline(a=0,b=1,lty=2)

```


# sessionInfo()
```{r}
sessionInfo()
```

