---
title: "Chap3_04-19-2019_Kazu"
author: "Kazu"
date: "4/19/2019"
output: 
  html_document: 
    keep_md: yes
editor_options: 
  chunk_output_type: console
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages(c("devtools","mvtnorm","loo","coda"),dependencies=TRUE)
#library(devtools)
#install_github("rmcelreath/rethinking",ref="Experimental")
```
# Chapter 3 Sampling the Imaginary
```{r Rcode 3.1}
Pr_Positive_Vampire <- 0.95
Pr_Positive_Mortal <- 0.01
Pr_Vampire <- 0.001
Pr_Positive <- Pr_Positive_Vampire * Pr_Vampire +
               Pr_Positive_Mortal * ( 1 - Pr_Vampire )
( Pr_Vampire_Positive <- Pr_Positive_Vampire*Pr_Vampire / Pr_Positive )
```
# 3.1. Sampling from a grid-approximate posterior
```{r R code 3.2}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prob_p <- rep( 1 , 1000 )
prob_data <- dbinom( 6 , size=9 , prob=p_grid )
posterior <- prob_data * prob_p
posterior <- posterior / sum(posterior)
```
```{r R code 3.3}
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
```
# Kazu's note on sample() at Rclub
```{r}
# normal sampling scirpt (equal probability)
sample(10,10)
# probability of each number is different (J's cript)
sample(10,10,replace=TRUE,prob=c(30,rep(1,9)))
# Youd do not need to sample numbers, but alphabet letters.
sample(c("A","B","C","D","E","F","G","H","I","J"),10,replace=TRUE,prob=c(30,rep(1,9)))
```
# Kazu's cheat sheet on this chapter
```{r include=FALSE}
# sampling from grid-approximated posterior
sample(p_grid,prob=posterior,size=1e4,replace=TRUE)
# simulation for model checking
## rbinom(n,size,prob)
rbinom(10000,size=9,prob=0.6) # globe toss as example. toss = 9, prob of water is 0.6
```


```{r R code 3.4}
plot( samples )
```

```{r R code 3.5}
library(rethinking)
dens( samples )
```
# 3.2. Sampling to summarize
```{r R code 3.6}
 # add up posterior probability where p < 0.5
sum( posterior[ p_grid < 0.5 ] )
```

```{r R code 3.7}
sum( samples < 0.5 ) / 1e4
```

```{r R code 3.8}
sum( samples > 0.5 & samples < 0.75 ) / 1e4
```

```{r R code 3.9}
quantile( samples , 0.8 )
```

```{r R code 3.10}
quantile( samples , c( 0.1 , 0.9 ) )
```

```{r R code 3.11}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prior <- rep(1,1000)
likelihood <- dbinom( 3 , size=3 , prob=p_grid )
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
samples <- sample( p_grid , size=1e4 , replace=TRUE , prob=posterior )
```

```{r R code 3.12}
 PI( samples , prob=0.5 )
```

```{r R code 3.13}
HPDI( samples , prob=0.5 )
```
# point estimates
```{r R code 3.14}
 p_grid[ which.max(posterior) ]
```
```{r R code 3.15}
 chainmode( samples , adj=0.01 )
```

```{r R code 3.16}
mean( samples )
median( samples )
```

```{r R code 3.17}
sum( posterior*abs( 0.5 - p_grid ) )
```
```{r R code 3.18}
 loss <- sapply( p_grid , function(d) sum( posterior*abs( d - p_grid ) ) )
```

```{r R code 3.19}
 p_grid[ which.min(loss) ]
```

# 3.3. Samplingtosimulateprediction
```{r R code 3.20}
 dbinom( 0:2 , size=2 , prob=0.7 )
```

```{r R code 3.21}
rbinom( 1 , size=2 , prob=0.7 )
```

```{r R code 3.22}
 rbinom( 10 , size=2 , prob=0.7 )
```

```{r R code 3.23}
dummy_w <- rbinom( 1e5 , size=2 , prob=0.7 )
table(dummy_w)/1e5
```

```{r R code 3.24}
dummy_w <- rbinom( 1e5 , size=9 , prob=0.7 )
simplehist( dummy_w , xlab="dummy water count" )
```
# (MO) for simulated data 
```{r R code 3.25}
 w <- rbinom( 1e4 , size=9 , prob=0.6 )
# 10000 simulated prediction of 9 globe tosses (size=9), assuming p=0.6

```

```{r R code 3.26}
 w <- rbinom( 1e4 , size=9 , prob=samples )
```

```{r}

```

```{r}

```

# 3.4. Summary

# 3.5 Practice
Easy. Theseproblemsusethesamplesfromtheposteriordistributionfortheglobetossingexample. 
```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prior <- rep( 1 , 1000 )
likelihood <- dbinom( 6 , size=9 , prob=p_grid )
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
set.seed(100)
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
```
This code will give you a specific set of samples, so that you can check your answers exactly.
Use the values in samples to answer the questions that follow.
3E1. How much posterior probability lies below p = 0.2?
```{r}
library(rethinking)
sample( p_grid , prob=posterior , size=10 , replace=TRUE ) # what is size?
dens(samples)
sum(samples[samples<0.2])/1e4 # divide the resulting count by the total number of samples (pg 54)
```
3E2. How much posterior probability lies above p = 0.8?
```{r}
sum(samples[samples>0.8])/1e4 # divide the resulting count by the total number of samples
```
3E3. How much posterior probability lies between p = 0.2 and p = 0.8? 3E4. 20% of the posterior probability lies below which value of p?
```{r}
sum(samples[samples>0.2 & samples<0.8])/1e4
```

3E5. 20% of the posterior probability lies above which value of p?
```{r}
quantile(samples,0.8)
```
3E6. Which values of p contain the narrowest interval equal to 66% of the posterior probability?
```{r}
 HPDI( samples , prob=0.66 )
```
3E7. Which values of p contain 66% of the posterior probability, assuming equal posterior probability both below and above the interval?
```{r}
PI(samples,prob=0.66)
```

3M1 Suppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.
```{r}
p_grid <- seq( from=0 , to=1 , length.out=1000 )
prior <- rep( 1 , 1000 )
likelihood <- dbinom( 8 , size=15 , prob=p_grid ) # change this
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
plot(posterior)
```

3M2 Draw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for p.
```{r}
samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )
dens(samples)
HPDI(samples,0.9)
```
3M3 Construct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in p. What is the probability of observing 8 water in 15 tosses?
```{r}
# learning rbinom funciton
rbinom( 10 , size=15 , prob=0.6 )
# 1e4 trials as did in R code 3.25
 w <- rbinom( 1e4 , size=15 , prob=0.6 ) # why prob=0.6?
# use 
 w2 <- rbinom( 1e4 , size=15 , prob=samples ) # length of "n" shoudl be same as one of prob?
 rbinom( 1e3 , size=15 , prob=samples ) # no
 table(w2)/1e4 # 0.1486
 simplehist(w2)
```
3M4 Using the posterior distribution constructed from the new (8/15) data, now calculate the probability of observing 6 water in 9 tosses.
```{r error=TRUE}
p_grid.3M4 <- seq( from=0 , to=1 , length.out=10000)
likelihood <- dbinom(6 , size=9 , prob=samples) # 
posterior <- likelihood * prior
posterior <- posterior / sum(posterior)
set.seed(100)
samples.3M4 <- sample( p_grid.3M4, prob=posterior , size=1e4 , replace=TRUE )
dens(samples.3M4)

table.3M4<-table(rbinom(1e4,size=9,samples.3M4))
table.3M4/1e4
# 0.0996 for 6 water in 9 toss
 simplehist(table.3M4)
```

3H1
```{r}
## R code 3.28
# data: gender (male=1, female=0)
birth1 <- c(1,0,0,0,1,1,0,1,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,
0,0,0,1,1,1,0,1,0,1,1,1,0,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,
1,1,0,1,0,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,1,1,0,
1,0,1,1,1,0,1,1,1,1) # first born from 100 two-child familes
birth2 <- c(0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,
1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,
1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,1,1,
0,0,0,1,1,1,0,0,0,0) # sedonc born from 100 two-child familes
# Ops! no need to type
library(rethinking)
data(homeworkch3)
sum(birth1) + sum(birth2) # total number of boy
```
## 3H1. Using grid approximation, compute the posterior distribution for the probability of a birth being a boy. Assume a uniform prior probability. Which parameter value maximizes the posterior probability?
```{r}
p_grid<-seq(from=0,to=1,length.out=1000) # 1000 grid points
prior <- rep(1,1000 ) # flat prior
boy<-sum(birth1)+sum(birth2)
likelihood3H1 <- dbinom(boy, size=200 , prob=p_grid ) # total is 200 children
posterior3H1 <- likelihood3H1 * prior 
posterior3H1 <- posterior3H1 / sum(posterior3H1)
plot(x=p_grid,y=posterior3H1)
p_grid[which.max(posterior3H1)] # 0.5545546
```
## 3H2. Using the sample funciton, draw 10,000 random parameter values from the posterior distribution you calculated above. Use these samples to estimate the 50%, 89%, and 97% highest posterior density intervals.
```{r}
samples3H2 <- sample( p_grid , prob=posterior3H1 , size=1e4 , replace=TRUE ) 
hist(samples3H2);dens(samples3H2)
HPDI(samples3H2,prob=0.5) # 0.5275275 0.5735736
HPDI(samples3H2,prob=0.89) # 0.4974975 0.6076076
HPDI(samples3H2,prob=0.97) # 0.4974975 0.6076076
# Rie found convinient way
HPDI(samples3H2,prob=c(0.5,0.89,0.97))
```
## 3H3. Use rbinom to simulate 10,000 replicates of 200 births. You should end up with 10,000 numbers, each one a count of boys out of 200 births. Compare the distribution of predicted numbers of boys to the actual count in the data (111 boys out of 200 births). There are many good ways to visualize the simulations, but the dens command is probably the easiest way in this case. Does it look like the model fits the data well? That is, does the distribution of predictions include the actual observation as a central, likely outcome?
```{r}
sims<-rbinom(10000,size=200,prob=samples3H2)
dens(sims)
dens(sims,main="dummy_boy",xlim=c(0,200))
abline(v=111);text(x=150,y=0.03,"111 boys");text(x=150,y=0.025,"out of 200 borns")
```
# 
## 3H4. Now compare 10,000 counts of boys from 100 simulated first borns only ot hte number of boys in the first birth, birth1. How does the model look in this light?
```{r}
sim.3H4<-rbinom(10000,size=100,prob=samples3H2)
dens(sim.3H4,main="dummy_boy",xlim=c(0,100))
abline(v=sum(birth1),col="blue");text(x=60,y=0.03,paste(sum(birth1),"observed boys"),col="blue");text(x=60,y=0.025, "out of first 100 borns",col="blue") # birth1 is off centered
HPDI(sim.3H4,.95)
# So whole dataset based model does not fit to the birth 1 data. 
# J's 
sum(sim.3H4==51)/length(sim.3H4) # ratio of observed number in simulation
sum(sim.3H4==median(sim.3H4))/length(sim.3H4) # ratio of median sim.3H4
```
## 3H5. The model assumes that sex of first and second births are independent. To check this assumption, focus now on second births that followed female first borns. Compare 10,000 simulated counts of boys to only those second births that followed girls. To do this correctly, you need to count the number of first borns who were girls and simulate the many births, 10,000 times. Compare the counts of boys in your simulations to the actual observed count of boys following girls. How does the model look in this light? Any guesses what is going on in these data?
```{r}
birth1F.birth2<-birth2[birth1==0] # second births that followed female first borns
sum(birth1F.birth2) # 39 boys 
# simulate the many births, 10000 times
sum(birth1==0) #49
sims.3H5<-rbinom(10000,size=49,prob=samples3H2)
# plot
dens(sims.3H5)
# compare this with observed data 39 boys in birth2 that followed female first borns
sum(sims.3H5==39)/1000 # 0.004
HPDI(sims.3H5,0.95) # 19~34. 39 is out of this range
```

